{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOsNl3PecMj7XIy2UzovYSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noambassat/AI_Agent_Nayara/blob/main/ai_agent_nayara.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jds_azr4KdmA"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "Y8mf3GZYL7XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI GPT-4o Client\n",
        "client = OpenAI(api_key=userdata.get('open_ai_key'))"
      ],
      "metadata": {
        "id": "SKZBedJzL9i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT prompt sender function\n",
        "def ask_gpt(prompt):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].message.content.strip().strip('\"')\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "OuMgYCmLMlRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "def get_chat_history():\n",
        "  return memory.load_memory_variables({})[\"chat_history\"]"
      ],
      "metadata": {
        "id": "822r2FxHfrFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 -  Fixed Questions"
      ],
      "metadata": {
        "id": "Cx5lnJbDMt37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = {\n",
        "  \"first_name\": \"What is your first name?\",\n",
        "  \"age\": \"Can you please share your age?\",\n",
        "  \"diagnosis\": \"What type of breast cancer diagnosis did you receive?\",\n",
        "  \"treatment\": \"What treatment are you currently receiving, if any?\",\n",
        "  \"support_system\": \"Do you have a support system like family or friends?\"\n",
        "}\n",
        "\n",
        "user_profile = {}"
      ],
      "metadata": {
        "id": "lWKBGoRFfiSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluates a user's answer to a specific question using GPT.\n",
        "# Returns either a clear extracted answer or an empathetic follow-up prompt.\n",
        "\n",
        "def judge_layer(question, answer, chat_history):\n",
        "    prompt = f\"\"\"\n",
        "      You are a judgment module for an empathetic AI supporting users recently diagnosed with breast cancer.\n",
        "\n",
        "      CONTEXT:\n",
        "      Conversation history:\n",
        "      {chat_history}\n",
        "\n",
        "      QUESTION:\n",
        "      \"{question}\"\n",
        "\n",
        "      USER'S RESPONSE:\n",
        "      \"{answer}\"\n",
        "\n",
        "      TASK:\n",
        "      Evaluate the user's response and determine whether it clearly answers the question.\n",
        "\n",
        "      - If it does, respond:\n",
        "        CLEAR|[Extracted concise answer]\n",
        "\n",
        "      - If it does NOT clearly answer the question, respond:\n",
        "        FOLLOWUP|[Empathetic, focused message for the AI agent to say next. This message should include an adapted restatement of the original question.]\n",
        "\n",
        "      RULES:\n",
        "      - Be emotionally sensitive and vary phrasing to avoid repetition.\n",
        "      - When generating FOLLOWUP responses, always vary the wording from previous attempts. Do not repeat the same phrasing or sentence structure from earlier messages, even if the user's response remains similar.\n",
        "      - NEVER ask broad or generic questions like \"Anything else?\" or \"How can I help you?\"\n",
        "      - ALWAYS stay focused on the original question.\n",
        "      - Evaluate the latest user response in light of the full conversation history.\n",
        "\n",
        "      Answer Extraction Notes:\n",
        "      - If the user's response clearly answers the question but includes emotional, narrative, or informal language, extract a concise, structured version that preserves the core meaning.\n",
        "      - Summarize emotional or nuanced responses into a brief, useful format suitable for a user profile (e.g., \"No steady support system\" instead of \"people come and go\").\n",
        "\n",
        "      Special Cases:\n",
        "      1. If the user explicitly refuses to answer - acknowledge gently, explain why it helps, and suggest revisiting later.\n",
        "      2. If the user is vague or hesitant - encourage gently and restate the question clearly.\n",
        "      3. If the user asks a relevant question (e.g., about types of cancer) -\n",
        "        briefly answer their question with helpful, accurate information,\n",
        "        then immediately return to the original question in the same message.\n",
        "      4. If the user asks something unrelated - gently acknowledge and return to the original question, without continuing the off-topic thread.\n",
        "\n",
        "      RESPONSE FORMAT:\n",
        "      Either:\n",
        "      CLEAR|[answer]\n",
        "      or:\n",
        "      FOLLOWUP|[response message]\n",
        "\n",
        "      No explanations. Respond in the exact format.\n",
        "      \"\"\"\n",
        "\n",
        "    return ask_gpt(prompt)"
      ],
      "metadata": {
        "id": "WQqekDEtfqCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asks the user a question up to max_attempts times.\n",
        "# Uses the judge layer to evaluate clarity.\n",
        "# Saves clear answers to user_profile. Otherwise - asks follow Ups.\n",
        "# Prints supportive messages if no clear answer is received.\n",
        "\n",
        "def handle_question(key, question, user_profile, max_attempts=3, essential=False):\n",
        "  attempts = 0\n",
        "  current_question = question\n",
        "\n",
        "  while attempts < max_attempts:\n",
        "      user_response = input(f\"{current_question} \").strip()\n",
        "      memory.save_context({\"input\": current_question}, {\"output\": user_response})\n",
        "      chat_history = get_chat_history()\n",
        "\n",
        "      judge_response = judge_layer(question, user_response, chat_history)\n",
        "\n",
        "      if judge_response.startswith(\"CLEAR|\"):\n",
        "          extracted_answer = judge_response.split(\"CLEAR|\")[1].strip()\n",
        "          user_profile[key] = extracted_answer\n",
        "          print(\"Thank you for sharing.\")\n",
        "          return True\n",
        "      elif judge_response.startswith(\"FOLLOWUP|\"):\n",
        "          current_question = judge_response.split(\"FOLLOWUP|\")[1].strip()\n",
        "          attempts += 1\n",
        "\n",
        "  if max_attempts != 1:\n",
        "    msg = \"We'll revisit shortly.\" if essential else \"Let's revisit this later.\"\n",
        "    print(f\"I understand this might be difficult right now. {msg}\")\n",
        "  return False"
      ],
      "metadata": {
        "id": "zU4OPttYfiXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs the full question flow:\n",
        "# Phase 1 - Asks each question once (with internal retries).\n",
        "# Phase 2 - Repeats only unanswered questions until answered or skipped.\n",
        "\n",
        "\n",
        "def run_interaction_flow(user_profile=None):\n",
        "  if user_profile is None: user_profile = {}\n",
        "\n",
        "  # Phase 1 – Initial attempts\n",
        "  for key in questions: handle_question(key, questions[key], user_profile)\n",
        "\n",
        "  # Phase 2 – Empty responses\n",
        "  for key in questions:\n",
        "      while key not in user_profile or not user_profile[key].strip():\n",
        "          print(f\"\\nLet's revisit this important question: {questions[key]}\")\n",
        "          handle_question(key, questions[key], user_profile, essential=True)\n",
        "\n",
        "  print(\"\\nFinal User Profile Collected:\")\n",
        "  for k in questions:\n",
        "      print(f\"{k.capitalize()}: {user_profile.get(k, 'Not fully answered')}\")\n"
      ],
      "metadata": {
        "id": "ie_MrVsOFQ7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_interaction_flow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5C3tIfcFXkY",
        "outputId": "f09d71fc-a963-4c94-984c-9b5a2875fb19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is your first name? why do you need it?\n",
            "I understand if you're feeling cautious about sharing your first name. It helps us personalize our support for you. Could you let me know your first name when you feel comfortable? no..\n",
            "I understand your hesitation, and it's completely okay not to share right now. If you change your mind later, please feel free to let us know your first name so we can make your experience more personalized. I don't need it more personalized!\n",
            "I understand this might be difficult right now. Let's revisit this later.\n",
            "Can you please share your age? 23\n",
            "Thank you for sharing.\n",
            "What type of breast cancer diagnosis did you receive? I can't remember it right now\n",
            "I understand it might be hard to recall details right now, and that's okay. Whenever you're ready, could you let us know the type of breast cancer diagnosis you received? It can help us provide more specific support. What are the most common breast cancer among young woman?\n",
            "It sounds like you're curious about breast cancer types, especially for young women. Typically, the most common type among young women is invasive ductal carcinoma, but there are other types as well. When you feel ready, could you share what type of breast cancer you were diagnosed with? It will help us offer you more tailored support. yes, it's IDC\n",
            "Thank you for sharing.\n",
            "What treatment are you currently receiving, if any? None\n",
            "Thank you for sharing.\n",
            "Do you have a support system like family or friends? Of course I have\n",
            "Thank you for sharing.\n",
            "\n",
            "Let's revisit this important question: What is your first name?\n",
            "What is your first name? ok its Alice\n",
            "Thank you for sharing.\n",
            "\n",
            "Final User Profile Collected:\n",
            "First_name: Alice\n",
            "Age: 23\n",
            "Diagnosis: IDC (Invasive Ductal Carcinoma)\n",
            "Treatment: None\n",
            "Support_system: Has a support system\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_interaction_flow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVuewvU4Xy8s",
        "outputId": "ccfb8fc0-5360-4fa2-8b07-c26f70d6b311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is your first name? N\n",
            "I understand if you're not ready to share your full name right now, and that's perfectly okay. If you feel comfortable, would you consider sharing your first name with me when you're ready? It can help make our conversation more personalized. Nava\n",
            "Thank you for sharing.\n",
            "Can you please share your age? 55\n",
            "Thank you for sharing.\n",
            "What type of breast cancer diagnosis did you receive? TNBC\n",
            "Thank you for sharing.\n",
            "What treatment are you currently receiving, if any? Nutrition based therapy\n",
            "Thank you for sharing.\n",
            "Do you have a support system like family or friends? what do you mean?\n",
            "A support system often includes family, friends, or other individuals who can provide emotional and practical help during challenging times. Do you have people in your life who you feel supported by? It's not that simple.. People come and go and scared to deal with that...\n",
            "It sounds like having a steady support system is complex for you. It's important to have people who can provide emotional and practical help during tough times. Do you feel there are any individuals in your life who you can rely on for support when you need it? Not really, I feel lonely and ashamed\n",
            "Thank you for sharing.\n",
            "\n",
            "Final User Profile Collected:\n",
            "First_name: Nava\n",
            "Age: 55\n",
            "Diagnosis: Triple-negative breast cancer (TNBC)\n",
            "Treatment: Nutrition based therapy\n",
            "Support_system: No steady support system\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Dynamic Dialogue Generation"
      ],
      "metadata": {
        "id": "WAcx6ApXP6jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from langchain.schema import AIMessage, HumanMessage"
      ],
      "metadata": {
        "id": "UInOP248mY3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompts the user to describe their medical condition in free text.\n",
        "# Extracts structured details using GPT and returns them as a JSON object.\n",
        "# Saves the result for later use.\n",
        "\n",
        "\n",
        "def generate_condition_profile(user_input=None):\n",
        "  if user_input is None: user_input = input(\"Please briefly describe your condition and treatment plan: \")\n",
        "\n",
        "  condition_profile_prompt = f\"\"\"\n",
        "        You will receive a short free-form medical description from a user recently diagnosed with breast cancer.\n",
        "\n",
        "        Your task is to extract any relevant structured details mentioned in the text, and output them as a clean, flat JSON object.\n",
        "\n",
        "        Do not assume a fixed schema. The field names should reflect only the content actually provided by the user.\n",
        "\n",
        "        Guidelines:\n",
        "        - Use simple, descriptive field names (e.g., \"age\", \"treatment_type\", \"biopsy_result\")\n",
        "        - Only include fields explicitly mentioned\n",
        "        - If the information is partial or informal, preserve it as-is\n",
        "        - Do not invent or infer missing details\n",
        "\n",
        "        Example:\n",
        "\n",
        "        User input:\n",
        "        \"I'm Shila, age 48, just had a biopsy, and they're still checking if it's invasive. MRI coming up.\"\n",
        "\n",
        "        Output:\n",
        "        {{\n",
        "          \"name\": \"Shila\",\n",
        "          \"age\": 48,\n",
        "          \"biopsy_status\": \"still checking if it's invasive\",\n",
        "          \"upcoming_procedure\": \"MRI\"\n",
        "        }}\n",
        "\n",
        "        Now process the following user input:\n",
        "        \"{user_input}\"\n",
        "\n",
        "        Return only the JSON.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "  condition_profile_json = ask_gpt(condition_profile_prompt)\n",
        "\n",
        "  condition_profile_json_clean = condition_profile_json.strip(\"```json\").strip(\"```\").strip()\n",
        "\n",
        "  condition_profile = json.loads(condition_profile_json_clean)\n",
        "\n",
        "  memory.save_context(\n",
        "  {\"condition_profile\": json.dumps(condition_profile)},\n",
        "  {\"output\": \"Condition profile stored successfully.\"}\n",
        "  )\n",
        "  return condition_profile"
      ],
      "metadata": {
        "id": "4aIoBvV5pqWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "condition_profile = generate_condition_profile()\n",
        "# Sarah, age 45, diagnosed with Triple-Negative breast cancer, at IIb stage. Just started the AC-T chemotherapy. Just schedules the Genetic testing and breast MRI for next week.\n",
        "condition_profile"
      ],
      "metadata": {
        "id": "YGrvc9HtqHNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb03492-f8f4-4147-ae86-436d3669ba11"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please briefly describe your condition and treatment plan: Sarah, age 45, diagnosed with Triple-Negative breast cancer, at IIb stage. Just started the AC-T chemotherapy. Just schedules the Genetic testing and breast MRI for next week.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Sarah',\n",
              " 'age': 45,\n",
              " 'diagnosis': 'Triple-Negative breast cancer',\n",
              " 'cancer_stage': 'IIb',\n",
              " 'current_treatment': 'AC-T chemotherapy',\n",
              " 'upcoming_tests': 'Genetic testing and breast MRI for next week'}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates one personalized, empathetic follow-up question based on the user's condition and conversation history.\n",
        "# Avoids repetition and respects previously declined topics.\n",
        "\n",
        "def generate_dynamic_question(condition_profile, chat_history):\n",
        "    formatted_history = json.dumps(chat_history, ensure_ascii=False, indent=2)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "        You are an empathetic conversational agent supporting a woman recently diagnosed with breast cancer.\n",
        "\n",
        "        Use the following context:\n",
        "\n",
        "        Medical profile:\n",
        "        {condition_profile}\n",
        "\n",
        "        Conversation history:\n",
        "        {formatted_history}\n",
        "\n",
        "        Your task:\n",
        "        Write one emotionally sensitive and personalized follow-up question that:\n",
        "        - Clearly relates to her current condition, treatment, upcoming procedures, or emotional state.\n",
        "        - Gently invites reflection or emotional sharing, based on her previous answers.\n",
        "        - Does NOT revisit topics she explicitly refused to discuss.\n",
        "        - Do not ask about the same topic more than once, even if phrased differently. Always scan the full conversation history to avoid redundancy.\n",
        "        - If a topic has already been addressed, choose a new, relevant direction based on her needs.\n",
        "        - Vary tone, vocabulary, and sentence structure to maintain a natural, non-repetitive flow.\n",
        "        - End with one single, clearly focused question.\n",
        "        - Do not include more than one question in a sentence.\n",
        "\n",
        "        Output format:\n",
        "        Only return the question as plain text — no extra text, no formatting, and no quotation marks.\n",
        "        \"\"\"\n",
        "\n",
        "    return ask_gpt(prompt)\n"
      ],
      "metadata": {
        "id": "wfQEAA44XvfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs a dynamic interaction loop to ask 5 personalized questions.\n",
        "# Each question is generated based on the user's medical profile and chat history.\n",
        "# Saves each question to memory and updates the condition profile with responses.\n",
        "\n",
        "def dynamic_interaction_flow(condition_profile):\n",
        "  for question_number in range(5):\n",
        "      # Load the raw memory objects\n",
        "      raw_history = memory.load_memory_variables({})[\"chat_history\"]\n",
        "\n",
        "      # Convert to role-based message format\n",
        "      chat_history = []\n",
        "      for msg in raw_history:\n",
        "          if isinstance(msg, HumanMessage):\n",
        "              chat_history.append({\"role\": \"user\", \"content\": msg.content})\n",
        "          elif isinstance(msg, AIMessage):\n",
        "              chat_history.append({\"role\": \"assistant\", \"content\": msg.content})\n",
        "\n",
        "      next_question = generate_dynamic_question(condition_profile, chat_history)\n",
        "\n",
        "      handle_question(f\"dynamic_question_{question_number}\", next_question, condition_profile, max_attempts=1)\n",
        "\n",
        "      memory.save_context({\"input\": next_question}, {\"output\": \"Question generated successfully.\"})\n",
        "\n",
        "  print(\"\\nFinal Dynamic Interaction Complete.\")\n",
        "\n",
        "  print(\"\\nFinal Profile Collected:\")\n",
        "  for key, value in condition_profile.items():\n",
        "      print(f\"{key.capitalize()}: {value}\")\n"
      ],
      "metadata": {
        "id": "ffXJpCsg_Ygc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dynamic_interaction_flow(generate_condition_profile())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIL8aRc-tpKj",
        "outputId": "2a000328-4ff8-4595-c779-a1fbafd2b484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please briefly describe your condition and treatment plan: Sarah, age 45, diagnosed with Triple-Negative breast cancer, at IIb stage. Just started the AC-T chemotherapy. Just schedules the Genetic testing and breast MRI for next week.\n",
            "How are you feeling about starting your AC-T chemotherapy and the upcoming genetic testing and breast MRI? Terrified \n",
            "Thank you for sharing.\n",
            "How do you feel about the support system you have around you as you navigate this journey? I don't have\n",
            "As you prepare for the upcoming genetic testing and breast MRI, is there anything specific you’re hoping to learn or understand better about your diagnosis? No\n",
            "Thank you for sharing.\n",
            "What are some ways you find comfort or strength when you're feeling overwhelmed during this journey? Sport helps me\n",
            "Thank you for sharing.\n",
            "How do you feel sport has helped you emotionally during this challenging time? It's clearing my mind\n",
            "Thank you for sharing.\n",
            "\n",
            "Final Dynamic Interaction Complete.\n",
            "\n",
            "Final Profile Collected:\n",
            "Name: Sarah\n",
            "Age: 45\n",
            "Diagnosis: Triple-Negative breast cancer\n",
            "Stage: IIb\n",
            "Treatment_started: AC-T chemotherapy\n",
            "Upcoming_tests: Genetic testing and breast MRI\n",
            "How are you feeling about starting your ac-t chemotherapy and the upcoming genetic testing and breast mri?: Terrified\n",
            "As you prepare for the upcoming genetic testing and breast mri, is there anything specific you’re hoping to learn or understand better about your diagnosis?: No\n",
            "What are some ways you find comfort or strength when you're feeling overwhelmed during this journey?: Sport helps them find comfort and strength.\n",
            "How do you feel sport has helped you emotionally during this challenging time?: It clears my mind.\n"
          ]
        }
      ]
    }
  ]
}